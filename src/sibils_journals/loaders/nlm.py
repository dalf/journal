"""NLM Catalog (Entrez journal list) loader."""

import logging
import re
from pathlib import Path
from typing import Optional

from ..models import DataSource, JournalDict
from ..normalizers import normalize_issn, normalize_title
from .utils import deduplicate_journals

logger = logging.getLogger(__name__)

# Pattern to split records
RECORD_SEPARATOR = re.compile(r"-{50,}")


def load_currently_indexed_issns(input_dir: Path) -> set[str]:
    """
    Load set of ISSNs for currently indexed MEDLINE journals.

    Reads the file generated by `download nlm` which contains
    ISSNs extracted from the NLM Catalog API for journals with
    currentindexingstatus="Y".

    Args:
        input_dir: Directory containing NLM data

    Returns:
        Set of ISSNs (may be empty if file not found)
    """
    path = input_dir / "nlm" / "currently_indexed_issns.txt"
    if not path.exists():
        logger.debug(f"Currently indexed ISSNs file not found: {path}")
        return set()

    indexed_issns = set()
    with open(path) as f:
        for line in f:
            issn = line.strip().upper()
            if issn:
                indexed_issns.add(issn)

    logger.info(f"  Loaded {len(indexed_issns):,} currently indexed ISSNs")
    return indexed_issns


def parse_nlm_record(record_text: str, allow_no_issn: bool = False) -> Optional[JournalDict]:
    """
    Parse a single NLM catalog record.

    Args:
        record_text: Text of a single record (between separator lines)
        allow_no_issn: If True, allow records without ISSN if they have NLM ID

    Returns:
        JournalDict or None if record is invalid
    """
    fields = {}
    for line in record_text.strip().split("\n"):
        if ": " in line:
            key, _, value = line.partition(": ")
            fields[key.strip()] = value.strip()

    # Get ISSNs
    issn_print = normalize_issn(fields.get("ISSN (Print)"), validate_checksum=False)
    issn_electronic = normalize_issn(fields.get("ISSN (Online)"), validate_checksum=False)

    # Get NLM ID
    nlm_id = fields.get("NlmId", "").strip() or None

    # Check if we have valid identifiers
    has_issn = issn_print or issn_electronic
    has_nlm_id = bool(nlm_id)

    if not has_issn and not (allow_no_issn and has_nlm_id):
        return None

    # Get title
    title = normalize_title(fields.get("JournalTitle"))
    if not title:
        return None

    # Extract abbreviations
    med_abbr = fields.get("MedAbbr", "").strip() or None
    iso_abbr = fields.get("IsoAbbr", "").strip() or None

    journal: JournalDict = {
        "title": title,
        "issn_print": issn_print,
        "issn_electronic": issn_electronic,
        "source": DataSource.NLM,
    }

    if nlm_id:
        journal["nlm_id"] = nlm_id

    # MedAbbr is the official MEDLINE abbreviation - store separately
    if med_abbr:
        journal["medline_abbreviation"] = med_abbr

    # IsoAbbr goes to alternative_titles (if different from MedAbbr)
    if iso_abbr and iso_abbr != med_abbr:
        journal["alternative_titles"] = [iso_abbr]

    return journal


def load_nlm_data(input_dir: Path, include_no_issn: bool = True) -> list[JournalDict]:
    """
    Load NLM Catalog journal data from J_Entrez.txt.

    The NLM Entrez journal list contains metadata for all journals in NCBI
    databases, including official title abbreviations (MedAbbr) used in citations.

    Why J_Entrez.txt instead of J_Medline.txt?
    ------------------------------------------
    - J_Medline.txt (~35k): Only journals currently indexed for MEDLINE
    - J_Entrez.txt (~41k): All journals in NCBI Entrez databases (MEDLINE + PMC + others)

    J_Entrez.txt includes major journals like "The Journal of Biological Chemistry"
    that are distributed via PMC and may not appear in J_Medline.txt.

    All journals are loaded to provide metadata enrichment (titles, abbreviations).
    The `is_medline_indexed` flag indicates whether a journal is currently
    indexed in MEDLINE (based on `currently_indexed_issns.txt` from `download nlm`).

    Journals without ISSNs are included if they have an NLM ID. The merger
    will later create synthetic identifiers for these records.

    See: https://www.nlm.nih.gov/bsd/serfile_addedinfo.html

    Args:
        input_dir: Directory containing NLM data
        include_no_issn: Include journals without ISSN (using NLM ID as identifier)

    Returns:
        List of normalized journal dictionaries
    """
    journals = []
    nlm_path = input_dir / "nlm" / "J_Entrez.txt"

    if not nlm_path.exists():
        logger.warning(f"NLM data not found at {nlm_path}, skipping...")
        return journals

    logger.info(f"Loading NLM Catalog data from: {nlm_path}")

    # Load currently indexed ISSNs (from API download)
    indexed_issns = load_currently_indexed_issns(input_dir)
    has_indexed_list = bool(indexed_issns)

    if has_indexed_list:
        logger.info("  Will mark currently indexed journals with is_medline_indexed=True")
    else:
        logger.warning("  No indexed ISSNs file found (run 'download nlm' to get current indexing status)")

    if include_no_issn:
        logger.info("  Including journals without ISSN (using NLM ID as identifier)")

    try:
        with open(nlm_path, encoding="utf-8") as f:
            content = f.read()

        # Split by separator lines
        records = RECORD_SEPARATOR.split(content)

        parsed = 0
        parsed_no_issn = 0
        parsed_indexed = 0
        skipped = 0

        for record_text in records:
            record_text = record_text.strip()
            if not record_text:
                continue

            journal = parse_nlm_record(record_text, allow_no_issn=include_no_issn)
            if journal:
                has_issn = journal.get("issn_print") or journal.get("issn_electronic")

                # Check if this journal is currently indexed in MEDLINE
                if has_indexed_list and has_issn:
                    journal_issns = {
                        journal.get("issn_print"),
                        journal.get("issn_electronic"),
                    } - {None}
                    is_indexed = bool(journal_issns & indexed_issns)
                    journal["is_medline_indexed"] = is_indexed
                    if is_indexed:
                        parsed_indexed += 1

                journals.append(journal)
                parsed += 1
                if not has_issn:
                    parsed_no_issn += 1
            else:
                skipped += 1

        logger.info(f"  Parsed {parsed:,} records ({parsed_no_issn:,} without ISSN, {parsed_indexed:,} currently indexed), skipped {skipped:,}")

    except Exception as e:
        logger.error(f"Error loading NLM data: {e}")
        import traceback

        logger.debug(traceback.format_exc())

    # Deduplicate within source
    journals = deduplicate_journals(journals, "NLM")

    logger.info(f"Loaded {len(journals):,} journals from NLM Catalog")
    return journals
